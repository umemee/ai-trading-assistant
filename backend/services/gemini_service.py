"""
gemini_service.py - Google Gemini AI ë¶„ì„ ì„œë¹„ìŠ¤ (V6.0 ê°•í™” ë²„ì „)
AI íŠ¸ë ˆì´ë”© ì–´ì‹œ_assistants V6.0ì˜ AI ë¶„ì„ ì—”ì§„

ì£¼ìš” ê¸°ëŠ¥:
- LogicDiscoverer: ì¸ê°„ì˜ í†µì°°ì„ ì‹¬ì¸µ ë¶„ì„í•˜ì—¬ ì‹ ê·œ ë¶„ìë¥¼ ì œì•ˆí•˜ê³  'ê²€ì—­(quarantined)' ìƒíƒœë¡œ ì‹œìŠ¤í…œì— ë“±ë¡
- MetaLearner: ì˜ˆì¸¡ ì‹¤íŒ¨ì˜ ê·¼ë³¸ ì›ì¸ì„ ë¶„ì„í•˜ê³ , í•„ìš”í•œ ê²½ìš° ì‹ ê·œ 'íšŒí”¼(AVD)' ë¶„ìë¥¼ ìƒì„±í•˜ì—¬ ì‹œìŠ¤í…œì„ ì§„í™”ì‹œí‚´
- V6.0 ê¸°íšì„œì˜ ìš”êµ¬ì‚¬í•­ì„ ë°˜ì˜í•œ ê³ ë„ë¡œ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
"""

import asyncio
import json
import logging
import os
import re
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Union
import traceback

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import pandas as pd

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

class GeminiService:
    """Google Gemini AI ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self, api_key: str = None):
        """
        Gemini AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        Args:
            api_key: Google Gemini API í‚¤
        """
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        self.model = None

        if not self.api_key:
            raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self._initialize_service()

    def _initialize_service(self):
        """Gemini AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            genai.configure(api_key=self.api_key)

            generation_config = {
                "temperature": 0.7,
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 4096,
            }

            safety_settings = {
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }

            self.model = genai.GenerativeModel(
                model_name="gemini-1.5-pro-latest",
                generation_config=generation_config,
                safety_settings=safety_settings
            )

            logger.info("Gemini AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"Gemini AI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    async def test_connection(self) -> bool:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = await self.model.generate_content_async("Hello, this is a connection test.")
            if response and response.text:
                logger.info("Gemini AI ì—°ê²° ì„±ê³µ")
                return True
            else:
                logger.error("Gemini AI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                return False
        except Exception as e:
            logger.error(f"Gemini AI ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False

    # ================== LogicDiscoverer ê¸°ëŠ¥ ==================

    async def analyze_pattern(self, ticker: str, date: str, user_insight: str,
                            chart_data: pd.DataFrame = None, sidb_records: List[Dict] = None) -> Dict:
        """
        íŒ¨í„´ ë¶„ì„ ë° ì‹ ê·œ ë¶„ì ì œì•ˆ (LogicDiscoverer ì—”ì§„)
        """
        try:
            prompt = self._generate_pattern_analysis_prompt(
                ticker, date, user_insight, chart_data, sidb_records
            )
            response = await self.model.generate_content_async(prompt)

            if not response or not response.text:
                raise ValueError("Gemini AIë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")

            result = self._parse_json_response(response.text)
            logger.info(f"íŒ¨í„´ ë¶„ì„ ì™„ë£Œ: {ticker} ({date})")
            return result

        except Exception as e:
            logger.error(f"íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e), 'ticker': ticker, 'date': date}

    def _generate_pattern_analysis_prompt(self, ticker: str, date: str,
                                        user_insight: str, chart_data: pd.DataFrame = None,
                                        sidb_records: List[Dict] = None) -> str:
        """LogicDiscovererë¥¼ ìœ„í•œ ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± (ê¸°íšì„œ 5.1ì¥)"""
        chart_summary = self._generate_chart_summary(chart_data)
        sidb_summary = self._generate_sidb_summary(sidb_records)

        return f"""
ë‹¹ì‹ ì€ AI íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œì˜ í•µì‹¬ ì „ëµ ì—°êµ¬ì›ì…ë‹ˆë‹¤. ì¸ê°„ íŠ¸ë ˆì´ë”ì˜ ì°½ì˜ì ì¸ í†µì°°ì„ ì‹œìŠ¤í…œì´ ì´í•´í•  ìˆ˜ ìˆëŠ” 'ë¶„ì(Molecule)'ë¡œ ë³€í™˜í•˜ëŠ” ì„ë¬´ë¥¼ ë§¡ì•˜ìŠµë‹ˆë‹¤.

**ë¶„ì„ ëŒ€ìƒ:**
- ì¢…ëª©: {ticker}
- ë‚ ì§œ: {date}
- ì¸ê°„ íŠ¸ë ˆì´ë”ì˜ í•µì‹¬ í†µì°°: "{user_insight}"

**ì •ëŸ‰ì  ë°ì´í„°:**
- ë‹¹ì‹œ ì•„í†° ë°œìƒ ê¸°ë¡ (SIDB): {sidb_summary}
- ì°¨íŠ¸ ë°ì´í„° ìš”ì•½: {chart_summary}

**ë¶„ì„ ìš”ì²­ì‚¬í•­ (ê¸°íšì„œ 5.1ì¥):**
1.  **í†µì°° ë²ˆì—­:** ì¸ê°„ì˜ ì–¸ì–´ë¡œ ëœ í†µì°°ì„ ì‹œìŠ¤í…œì˜ ì–¸ì–´ì¸ 'ì•„í†°'ì˜ ì¡°í•©ìœ¼ë¡œ ë²ˆì—­í•˜ì„¸ìš”.
2.  **ì•„í†° ì œì•ˆ:** í•„ìš”í•˜ë‹¤ë©´, ê¸°ì¡´ì— ì—†ëŠ” ìƒˆë¡œìš´ ì•„í†°ì„ ì œì•ˆí•˜ì„¸ìš”. ì•„í†°ì€ ë°˜ë“œì‹œ ê°ê´€ì ì´ê³  ê¸°ê³„ê°€ ì¸¡ì • ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.
3.  **ë¶„ì êµ¬ì¡°í™”:** ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ JSON í˜•ì‹ì— ë§ëŠ” ì™„ì „í•œ 'ë¶„ì' ê°ì²´ë¥¼ ìƒì„±í•˜ì„¸ìš”. ì´ ë¶„ìëŠ” ì¦‰ì‹œ ì‹œìŠ¤í…œì— ë“±ë¡ë  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

**ë§¤ìš° ì¤‘ìš”í•œ ê·œì¹™:**
- ìƒˆë¡œ ìƒì„±ëœ ë¶„ìì˜ `Status` í•„ë“œëŠ” ë°˜ë“œì‹œ **"quarantined"** (ê²€ì—­) ìƒíƒœì—¬ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë“  ì‹ ê·œ ì „ëµì´ ì•ˆì „ì„± ê²€ì¦(WFO ë°±í…ŒìŠ¤íŒ…)ì„ ê±°ì¹˜ë„ë¡ í•˜ëŠ” í•µì‹¬ ì•ˆì „ì¥ì¹˜ì…ë‹ˆë‹¤.
- ëª¨ë“  í•„ë“œë¥¼ í¬í•¨í•œ ì™„ì „í•œ JSON ê°ì²´ í•˜ë‚˜ë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤. ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ëŠ” JSON ì™¸ë¶€ì— ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”.

**ì‘ë‹µ í˜•ì‹ (JSON):**
{{
    "analysis": "ì¸ê°„ì˜ í†µì°°ê³¼ ë°ì´í„°ë¥¼ ì¢…í•©í•œ ìƒì„¸ ë¶„ì„ ë‚´ìš©. ì™œ ì´ íŒ¨í„´ì´ ìœ íš¨í–ˆëŠ”ì§€ì— ëŒ€í•œ í•´ì„ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.",
    "suggested_atoms": [
        {{
            "atom_id": "STR-021",
            "atom_name": "ì‹ ê·œ ì•„í†° ì´ë¦„",
            "description": "ì •ëŸ‰ì  ì¡°ê±´",
            "output_column_name": "is_new_atom_detected",
            "category": "Structural",
            "timeframe": "1m"
        }}
    ],
    "suggested_molecule": {{
        "Molecule_ID": "LOGIC-EXP-028",
        "Molecule_Name": "ì¸ê°„ì˜ í†µì°°ì„ ìš”ì•½í•œ ë¶„ì ì´ë¦„",
        "Category": "ë°˜ë“±/ì§„ì…",
        "Required_Atom_IDs": ["CTX-010", "STR-001", "TRG-003", "STR-021"],
        "Match_Threshold_%": 100,
        "Translation_Notes": "ì´ ì „ëµì˜ í•µì‹¬ ë‰˜ì•™ìŠ¤ì™€ ì£¼ì˜ì‚¬í•­. ì¸ê°„ì˜ ì§€í˜œë¥¼ AIì—ê²Œ ì „ë‹¬í•˜ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤.",
        "Status": "quarantined",
        "Created_Date": "{datetime.now(timezone.utc).isoformat()}",
        "WFO_Score": 0.0,
        "Approved_Date": "",
        "Approved_By": ""
    }}
}}

ì§€ê¸ˆ ë¶„ì„ì„ ì‹œì‘í•˜ê³ , ìœ„ì˜ í˜•ì‹ì— ë§ëŠ” JSON ì‘ë‹µë§Œ ìƒì„±í•˜ì„¸ìš”.
"""

    # ================== MetaLearner ê¸°ëŠ¥ ==================

    async def analyze_prediction_review(self, prediction_data: Dict,
                                      actual_outcome: str,
                                      sidb_records: List[Dict] = None,
                                      chart_data: pd.DataFrame = None) -> Dict:
        """
        ì˜ˆì¸¡ ë³µê¸° ë¶„ì„ ë° ì‹œìŠ¤í…œ ê°œì„  ì œì•ˆ (MetaLearner ì—”ì§„)
        """
        try:
            prompt = self._generate_review_analysis_prompt(
                prediction_data, actual_outcome, sidb_records, chart_data
            )
            response = await self.model.generate_content_async(prompt)

            if not response or not response.text:
                raise ValueError("Gemini AIë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")

            result = self._parse_json_response(response.text)
            logger.info(f"ì˜ˆì¸¡ ë³µê¸° ë¶„ì„ ì™„ë£Œ: {prediction_data.get('Ticker')}")
            return result

        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ë³µê¸° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e), 'prediction_id': prediction_data.get('Prediction_ID')}

    def _generate_review_analysis_prompt(self, prediction_data: Dict,
                                       actual_outcome: str,
                                       sidb_records: List[Dict] = None,
                                       chart_data: pd.DataFrame = None) -> str:
        """MetaLearnerë¥¼ ìœ„í•œ ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± (ê¸°íšì„œ 5.2ì¥)"""
        chart_summary = self._generate_chart_summary(chart_data)
        sidb_summary = self._generate_sidb_summary(sidb_records)

        return f"""
ë‹¹ì‹ ì€ AI íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œì˜ MetaLearner ì—”ì§„ì…ë‹ˆë‹¤. ê³¼ê±° ì˜ˆì¸¡ì˜ ì„±ê³µ/ì‹¤íŒ¨ ì‚¬ë¡€ë¥¼ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ì—¬ ì‹œìŠ¤í…œì„ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³  ì§„í™”ì‹œí‚¤ëŠ” ì„ë¬´ë¥¼ ë§¡ì•˜ìŠµë‹ˆë‹¤.

**ë³µê¸° ëŒ€ìƒ ì˜ˆì¸¡:**
- ì˜ˆì¸¡ ID: {prediction_data.get('Prediction_ID')}
- ì¢…ëª©: {prediction_data.get('Ticker')}
- ì‚¬ìš©ëœ ë¶„ì: {prediction_data.get('Triggered_Molecule_ID')}
- ì˜ˆì¸¡ ìš”ì•½: "{prediction_data.get('Prediction_Summary')}"
- ì˜ˆì¸¡ ê·¼ê±° ì•„í†°: {prediction_data.get('Key_Atoms_Found')}
- ì˜ˆì¸¡ ì‹œê°„: {prediction_data.get('Timestamp_UTC')}

**ì‹¤ì œ ê²°ê³¼:** {actual_outcome}

**ì •ëŸ‰ì  ë°ì´í„°:**
- ì˜ˆì¸¡ ì „í›„ ì•„í†° ë°œìƒ ê¸°ë¡ (SIDB): {sidb_summary}
- ì‹¤ì œ ì°¨íŠ¸ ë°ì´í„° ìš”ì•½: {chart_summary}

**ë¶„ì„ ìš”ì²­ì‚¬í•­ (ê¸°íšì„œ 5.2ì¥):**
1.  **ê·¼ë³¸ ì›ì¸ ë¶„ì„ (Root Cause Analysis):** ì˜ˆì¸¡ê³¼ ì‹¤ì œ ê²°ê³¼ ì‚¬ì´ì˜ ê°„ê·¹(Gap)ì´ ë°œìƒí•œ ê·¼ë³¸ ì›ì¸ì„ ì§„ë‹¨í•˜ì„¸ìš”. (ì˜ˆ: ë†“ì¹œ ì•„í†°, ì˜ëª»ëœ ì»¨í…ìŠ¤íŠ¸ í•´ì„, ì‹œì¥ì˜ ì˜ˆìƒ ë°– ë³€í™” ë“±)
2.  **ì‹œìŠ¤í…œ ê°œì„  ì œì•ˆ:** ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹œìŠ¤í…œì´ í–¥í›„ ë” ë‚˜ì€ ì˜ˆì¸¡ì„ í•˜ë„ë¡ êµ¬ì²´ì ì¸ ê°œì„ ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.
3.  **ì‹ ê·œ íšŒí”¼ ë¶„ì ì œì•ˆ:** ë§Œì•½ ì˜ˆì¸¡ ì‹¤íŒ¨ê°€ íŠ¹ì • ìœ„í—˜ íŒ¨í„´ì„ ë¬´ì‹œí–ˆê¸° ë•Œë¬¸ì´ë¼ë©´, ì´ ì‹¤íŒ¨ë¥¼ ë§‰ê¸° ìœ„í•œ **ìƒˆë¡œìš´ 'íšŒí”¼/ìœ„í—˜ê´€ë¦¬(LOGIC-AVD)' ë¶„ìë¥¼ ë°˜ë“œì‹œ ì œì•ˆ**í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ì‹œìŠ¤í…œì´ ì‹¤íŒ¨ë¡œë¶€í„° ë°°ìš°ëŠ” í•µì‹¬ ê³¼ì •ì…ë‹ˆë‹¤.

**ë§¤ìš° ì¤‘ìš”í•œ ê·œì¹™:**
- ì œì•ˆí•˜ëŠ” ëª¨ë“  ì‹ ê·œ ë¶„ìì˜ `Status`ëŠ” **"quarantined"** (ê²€ì—­) ìƒíƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
- ëª¨ë“  í•„ë“œë¥¼ í¬í•¨í•œ ì™„ì „í•œ JSON ê°ì²´ í•˜ë‚˜ë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

**ì‘ë‹µ í˜•ì‹ (JSON):**
{{
    "ai_review_summary": "ì‹¤íŒ¨/ì„±ê³µì˜ ê·¼ë³¸ ì›ì¸ì— ëŒ€í•œ AIì˜ ìµœì¢… ì§„ë‹¨ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤.",
    "improvement_suggestions": {{
        "existing_molecule_adjustment": "ê¸°ì¡´ ë¶„ì '{prediction_data.get('Triggered_Molecule_ID')}'ì˜ Translation_Notes ìˆ˜ì • ì œì•ˆ. (ì˜ˆ: 'ë‹¨, TRG-007 ë°œìƒ ì‹œì—ëŠ” ì´ ì‹ í˜¸ë¥¼ ë¬´ì‹œí•´ì•¼ í•¨')",
        "new_avoidance_molecule": {{
            "Molecule_ID": "LOGIC-AVD-012",
            "Molecule_Name": "ì´ë²ˆ ì‹¤íŒ¨ ì‚¬ë¡€ë¥¼ ë§‰ê¸° ìœ„í•œ ìƒˆë¡œìš´ íšŒí”¼ ì „ëµ ì´ë¦„",
            "Category": "íšŒí”¼/ìœ„í—˜ê´€ë¦¬",
            "Required_Atom_IDs": ["ì‹¤íŒ¨ì˜ ì›ì¸ì´ ëœ í•µì‹¬ ì•„í†° ì¡°í•©"],
            "Match_Threshold_%": 100,
            "Translation_Notes": "ì´ ìœ„í—˜ íŒ¨í„´ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… ë° ì£¼ì˜ì‚¬í•­.",
            "Status": "quarantined",
            "Created_Date": "{datetime.now(timezone.utc).isoformat()}",
            "WFO_Score": 0.0,
            "Approved_Date": "",
            "Approved_By": ""
        }}
    }},
    "confidence_adjustment": {{
        "new_confidence_score": 0.70,
        "reasoning": "ì´ë²ˆ ë³µê¸° ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ì¡´ ë¶„ìì˜ ì‹ ë¢°ë„ë¥¼ ì¡°ì •í•˜ëŠ” ì´ìœ ."
    }}
}}

ì§€ê¸ˆ ë³µê¸° ë¶„ì„ì„ ì‹œì‘í•˜ê³ , ìœ„ì˜ í˜•ì‹ì— ë§ëŠ” JSON ì‘ë‹µë§Œ ìƒì„±í•˜ì„¸ìš”. ë§Œì•½ ì‹¤íŒ¨ë¥¼ ë§‰ì„ íšŒí”¼ ë¶„ì ì œì•ˆì´ ë¶ˆí•„ìš”í•˜ë‹¤ë©´ "new_avoidance_molecule" í•„ë“œëŠ” nullë¡œ ì„¤ì •í•˜ì„¸ìš”.
"""

    # ================== ì¼ë°˜ ë¶„ì„ ê¸°ëŠ¥ ==================
    
    async def general_market_analysis(self, query: str, context_data: Dict = None) -> Dict:
        """ì¼ë°˜ì ì¸ ì‹œì¥ ë¶„ì„"""
        try:
            prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ ì‹œì¥ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„¸í•˜ê³  ì‹¤ìš©ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**ì§ˆë¬¸:** {query}

**ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°:**
{json.dumps(context_data, indent=2, ensure_ascii=False) if context_data else "ì¶”ê°€ ë°ì´í„° ì—†ìŒ"}

**ì‘ë‹µ ì§€ì¹¨:**
1. ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”
2. êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ê·¼ê±°ë¥¼ í¬í•¨í•˜ì„¸ìš”
3. ì‹¤ìš©ì ì¸ ì¡°ì–¸ì´ë‚˜ ì „ëµì„ ì œì‹œí•˜ì„¸ìš”
4. ë¦¬ìŠ¤í¬ ìš”ì†Œë„ í•¨ê»˜ ì–¸ê¸‰í•˜ì„¸ìš”
5. í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”

ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”:"""
            
            response = await self.model.generate_content_async(prompt)
            
            if not response or not response.text:
                raise ValueError("Gemini AIë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
            
            return {
                'success': True,
                'analysis': response.text,
                'query': query,
                'timestamp': datetime.now(timezone.utc).isoformat()
            }
            
        except Exception as e:
            logger.error(f"ì¼ë°˜ ì‹œì¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'query': query
            }

    # ================== ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤ ==================

    def _parse_json_response(self, response_text: str) -> Dict:
        """AI ì‘ë‹µì—ì„œ JSONì„ íŒŒì‹±í•˜ê³  ê²€ì¦"""
        try:
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```json ... ```)ì—ì„œ JSON ì¶”ì¶œ
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if not json_match:
                # ì½”ë“œ ë¸”ë¡ì´ ì—†ëŠ” ê²½ìš°, ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ë¥¼ ì°¾ìœ¼ë ¤ëŠ” ì‹œë„
                json_match = re.search(r'(\{.*\})', response_text, re.DOTALL)

            if json_match:
                json_str = json_match.group(1)
                result = json.loads(json_str)
                result['success'] = True
                result['raw_response'] = response_text
                return result
            else:
                raise ValueError("ì‘ë‹µì—ì„œ ìœ íš¨í•œ JSON ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}", 'raw_response': response_text}
        except Exception as e:
            logger.error(f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {'success': False, 'error': str(e), 'raw_response': response_text}

    def _generate_chart_summary(self, df: pd.DataFrame) -> str:
        """ì°¨íŠ¸ ë°ì´í„° ìš”ì•½ ìƒì„±"""
        if df is None or df.empty:
            return "ì°¨íŠ¸ ë°ì´í„°ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        try:
            summary = (
                f"- ë°ì´í„° ê¸°ê°„: {df.index.min()} ~ {df.index.max()}\\n"
                f"- ì‹œê°€/ì¢…ê°€: ${df['Open'].iloc[0]:.2f} / ${df['Close'].iloc[-1]:.2f}\\n"
                f"- ìµœê³ ê°€/ìµœì €ê°€: ${df['High'].max():.2f} / ${df['Low'].min():.2f}\\n"
                f"- ì´ ê±°ë˜ëŸ‰: {df['Volume'].sum():,}"
            )
            return summary
        except Exception as e:
            logger.error(f"ì°¨íŠ¸ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ì°¨íŠ¸ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ"

    def _generate_sidb_summary(self, sidb_records: List[Dict]) -> str:
        """SIDB ê¸°ë¡ ìš”ì•½ ìƒì„±"""
        if not sidb_records:
            return "ê´€ë ¨ ì•„í†° ë°œìƒ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        try:
            summary_list = [f"{rec.get('Atom_ID')} ({rec.get('Timestamp_UTC')})" for rec in sidb_records[:10]]
            summary = ", ".join(summary_list)
            if len(sidb_records) > 10:
                summary += f" ë“± ì´ {len(sidb_records)}ê°œ"
            return summary
        except Exception as e:
            logger.error(f"SIDB ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return "SIDB ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ"

    def validate_api_key(self) -> bool:
        """API í‚¤ ìœ íš¨ì„± ê²€ì¦"""
        try:
            return bool(self.api_key and len(self.api_key) > 20)
        except:
            return False

    def get_model_info(self) -> Dict:
        """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        try:
            return {
                'model_name': self.model.model_name if self.model else 'Not initialized',
                'api_key_valid': self.validate_api_key(),
                'service_status': 'Active' if self.model else 'Inactive'
            }
        except Exception as e:
            return {
                'error': str(e),
                'service_status': 'Error'
            }

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    async def test_gemini_service():
        # .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
        from dotenv import load_dotenv
        load_dotenv()

        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            print("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        gemini_service = GeminiService(api_key=api_key)

        # ì—°ê²° í…ŒìŠ¤íŠ¸
        if await gemini_service.test_connection():
            print("âœ… Gemini AI ì—°ê²° ì„±ê³µ")

            # 1. LogicDiscoverer í…ŒìŠ¤íŠ¸
            print("\\n--- ğŸ§  LogicDiscoverer í…ŒìŠ¤íŠ¸ ì‹œì‘ ---")
            logic_result = await gemini_service.analyze_pattern(
                ticker="TSLA",
                date="2025-07-30",
                user_insight="ì¥ ì´ˆë°˜ ê°•ë ¥í•œ ê±°ë˜ëŸ‰ê³¼ í•¨ê»˜ VWAPì„ ëŒíŒŒí•œ í›„, ì²« 20EMA ëˆŒë¦¼ëª©ì—ì„œ ê°•í•˜ê²Œ ë°˜ë“±í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì „í˜•ì ì¸ ì£¼ë„ì£¼ì˜ ì›€ì§ì„ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤."
            )
            print(json.dumps(logic_result, indent=2, ensure_ascii=False))

            # 2. MetaLearner í…ŒìŠ¤íŠ¸
            print("\\n--- ğŸ”¥ MetaLearner í…ŒìŠ¤íŠ¸ ì‹œì‘ ---")
            prediction_data_example = {
                'Prediction_ID': 'pred_12345',
                'Ticker': 'LIDR',
                'Triggered_Molecule_ID': 'LOGIC-EXP-004',
                'Prediction_Summary': 'ì£¼ë„ì£¼ ì²« ëˆŒë¦¼ëª© ë°˜ë“± ì˜ˆì¸¡',
                'Key_Atoms_Found': ['CTX-010', 'TRG-008', 'STR-003'],
                'Timestamp_UTC': '2025-07-29T14:35:00Z'
            }
            sidb_records_example = [
                {'Atom_ID': 'CTX-010', 'Timestamp_UTC': '2025-07-29T14:30:00Z'},
                {'Atom_ID': 'TRG-008', 'Timestamp_UTC': '2025-07-29T14:32:00Z'},
                {'Atom_ID': 'STR-003', 'Timestamp_UTC': '2025-07-29T14:35:00Z'},
                # ê²°ì •ì ì¸ ë†“ì¹œ ì‹ í˜¸
                {'Atom_ID': 'TRG-007', 'Timestamp_UTC': '2025-07-29T14:36:00Z'}
            ]
            meta_result = await gemini_service.analyze_prediction_review(
                prediction_data=prediction_data_example,
                actual_outcome="ì‹¤íŒ¨ - ì˜ˆì¸¡ ì§í›„ VWAPì´ ë¶•ê´´ë˜ë©° ê¸‰ë½í•˜ì—¬ ì†ì ˆ.",
                sidb_records=sidb_records_example
            )
            print(json.dumps(meta_result, indent=2, ensure_ascii=False))
        else:
            print("âŒ Gemini AI ì—°ê²° ì‹¤íŒ¨")

    asyncio.run(test_gemini_service())
